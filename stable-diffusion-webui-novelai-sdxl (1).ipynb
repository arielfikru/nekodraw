{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# NovelAi stable-diffusion-webui+api+sdxl\n---\n**version: 1.6.0  •  python: 3.10.6  •  torch: 2.0.1+cu118  •  xformers: 0.0.21  •  gradio: 3.41.2**\n- 发布地址 [kaggle stable-diffusion-webui-novelai](https://www.kaggle.com/code/yiyiooo/stable-diffusion-webui-novelai)\n- 这是一个用于快速体验ai绘画项目 [stable-diffusion-webui](https://github.com/AUTOMATIC1111/stable-diffusion-webui) 的笔记本，你可以直接启动就能在线体验ai绘图的乐趣。 \n- kaggle和colab都是AI学习平台，请勿浪费计算资源，如果有需求，可以考虑AutoDL这类租用显卡的平台或者colab付费使用。\n- 在保持可以免配置直接启动的情况下也提供了很多可自定义的配置，在下方的配置项里，请自行查看。 \n- 同时也为新人提供了一份基础的帮助文档，包含了一些使用中可能遇到的问题，如果使用过程中有什么疑问，不妨先看看帮助文档。\n- 如果你需要在此脚本上修改再发布，请随意，但请遵守相关法律法规，文明使用。\n- 使用时如果遇到问题，尽可能通过帮助文档或者参考已有内容尝试自己解决。\n- Q群 [816545732](http://qm.qq.com/cgi-bin/qm/qr?_wv=1027&k=OGQydingTPku9M_myV_cscWv6MVaCSde&authKey=RFadQ18FgReFkx7CRs8SNk4vHpxHz%2FD2ojHL3433MehuQOBlnG0hhWFIo8AX%2BFRU&noverify=0&group_code=816545732) ，这是我建的新群，如果有需要，可以进群，其实这个笔记已经非常简洁了，进群大概也不会有啥帮助。","metadata":{}},{"cell_type":"markdown","source":"## 重要文件列表\n\n- **这个列表仅加载一次 且会等待加载完成再开始安装sd**\n- ```[]```内的是下载文件的目标目录，可以是相对目录也可以是觉得路径\n- ```[]```的下一行就是文件列表，可以是下载地址、git仓库、文件路径、文件夹路径，且支持通配符\n- 如果需要对下载的文件重命名，可以在下载链接前面写上文件名后加一个```:```分开文件名和下载地址\n- 如果需要下载到其他目录，可以使用同样的格式写其他目录","metadata":{}},{"cell_type":"code","source":"before_downloading = '''# 这个列表仅加载一次 且会等待加载完成再开始安装sd\n[extensions] # 插件\nhttps://github.com/etherealxx/batchlinks-webui.git\n\n# 如果你有模型文件需要在启动前加载，可以写在这个下面对应位置\n\n[models/Stable-diffusion]                # 大模型列表\n\n[models/hypernetworks]                   # hypernetworks文件列表\n\n[models/embeddings]                      # embeddings文件列表\n\n[models/Lora]                            # Lora文件列表\n\n[models/VAE]                             # VAE文件列表\nhttps://huggingface.co/Norisuke193/kl-f8-anime2/resolve/main/kl-f8-anime2.vae.pt\n\n[extensions/sd-webui-controlnet/models] # controlnet插件的模型列表\n\n'''\n\n!wget https://huggingface.co/datasets/artdwn/sd1x/resolve/main/token.txt -O /kaggle/working/ngrok.txt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 普通文件列表\n\n- **这个列表仅加载一次 且不会等待加载完成**\n- ```[]```内的是下载文件的目标目录，可以是相对目录也可以是觉得路径\n- ```[]```的下一行就是文件列表，可以是下载地址、git仓库、文件路径、文件夹路径，且支持通配符\n- 如果需要对下载的文件重命名，可以在下载链接前面写上文件名后加一个```:```分开文件名和下载地址\n- 如果需要下载到其他目录，可以使用同样的格式写其他目录","metadata":{}},{"cell_type":"code","source":"async_downloading='''# 这个列表仅加载一次 且不会等待加载完成\n[extensions] # 插件 如果你没有使用ngrok或者frpc，请不要把插件放在这里加载，因为这里的文件可能在webui启动后才加载完成\n\n[models/Stable-diffusion]                # 大模型列表\n\n[models/hypernetworks]                   # hypernetworks文件列表\n\n[models/embeddings]                      # embeddings文件列表\n\n[models/Lora]                            # Lora文件列表\n\n[models/VAE]                             # VAE文件列表\n\n\n[extensions/sd-webui-controlnet/models] # controlnet插件的模型列表\n\n'''\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 按顺序加载的重要文件列表\n\n- **这个列表每次 run all 启动都会加载一次，且一定按照顺序加载后才启动webui**\n- ```[]```内的是下载文件的目标目录，可以是相对目录也可以是觉得路径\n- ```[]```的下一行就是文件列表，可以是下载地址、git仓库、文件路径、文件夹路径，且支持通配符\n- 如果需要对下载的文件重命名，可以在下载链接前面写上文件名后加一个```:```分开文件名和下载地址\n- 如果需要下载到其他目录，可以使用同样的格式写其他目录","metadata":{}},{"cell_type":"code","source":"before_start_sync_downloading = ''' # 这个列表每次 run all 启动都会加载一次，且一定按照顺序加载\n\n# 如果你需要每次启动都加载一下文件，可以写在这。（比如测试路径是否正确的时候）\n\n[models/Stable-diffusion]                # 大模型列表\nepiC.safetensors:https://civitai.com/api/download/models/172306\n\n[models/hypernetworks]                   # hypernetworks文件列表\n\n[models/embeddings]                      # embeddings文件列表\n\n[models/Lora]                            # Lora文件列表\nyuukiAsuna_SAO.safetensors:https://civitai.com/api/download/models/157655\ngenshinImpact_Pack.safetensors:https://civitai.com/api/download/models/173569\n\n[models/VAE]                             # VAE文件列表\nhttps://huggingface.co/Norisuke193/kl-f8-anime2/resolve/main/kl-f8-anime2.vae.pt\n\n[extensions/sd-webui-controlnet/models] # controlnet插件的模型列表\n\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## webui 启动参数\n- 所有的参数都会在启动时传入\n- 可以在前面加```#```来屏蔽某个参数\n- 端口参数需要在下一个代码块的```webuiPort```处修改","metadata":{}},{"cell_type":"code","source":"sd_start_args='''\n# --ckpt=mg-Tender.safetensors # 默认模型名称，路径不能包含空格\n--disable-safe-unpickle \n--deepdanbooru \n--no-hashing \n--no-download-sd-model \n--administrator\n--skip-torch-cuda-test \n--skip-version-check \n--disable-nan-check\n# --opt-sdp-attention \n--opt-sdp-no-mem-attention \n--xformers-flash-attention\n--xformers\n--api \n--listen\n--lowram\n--no-gradio-queue\n# --share # 默认的内网穿透在kaggle和colab都已经不可用，请考虑其他方案\n--disable-console-progressbars\n--no-half-vae \n# --no-half  #关闭半精度\n# --enable-console-prompts\n# --nowebui\n# --api-auth=2333:6666  # api密码\n# --gradio-auth=2333:6666 # webui密码\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"useGooglrDrive = False # 连接到谷歌云盘 在google colab环境才会生效\n#Ngrok\nuseNgrok=True # 非必填 是否使用ngrok作为公网访问地址\n#Frpc\nuseFrpc=False # 开启frp将不能启动\n\n#文件或直接填配置\nngrok_config_or_file = '''\n/kaggle/working/ngrok.txt\n'''\nfrp_config_or_file = '''\n{input_path}/configs/frpc_litechat.ini\n'''\nfrp_ssl_dir = '''\n{input_path}/configs/litechat_nginx\n'''\n\n# 配置启动参数\nserver_port=7860 # webui 默认端口\n\n# 仓库地址 这是修改过界面布局顺序的webui，不定期同步到官方版本\n# 如果要使用官方版本，改成这个： https://github.com/AUTOMATIC1111/stable-diffusion-webui\n#sd_git_repo='https://github.com/viyiviyi/stable-diffusion-webui.git -b local' \n# 配置文件，包括webui的设置和UI默认值，如果要自定义，fork这个仓库后修改并把地址替换这个地址\n#sd_config_git_repu = 'https://github.com/viyiviyi/sd-configs.git'\n# 设置文件保存路径 当使用谷歌云盘时非常有用\n#setting_file = '{output_path}/configs/config.json'\n#ui_config_file = '{output_path}/configs/ui-config.json'\n\n# 这是配置文件夹同步的相关配置\n# 需要在huggingface创建一个数据集(datasets) 然后把数据集的名称(在页面上有复制的按钮)填到 huggingface_repo \n# 需要获取 token 填到 huggingface_token 获取的地址是： https://huggingface.co/settings/tokens\n#huggingface_token = '{input_path}/configs/huggingface_token.txt'\n#huggingface_repo = 'viyi/sdwui-log'\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"link_instead_of_copy = True # 下载或加载Input的文件时是使用链接还是复制的方式加载到目标目录\nhidden_console_info = False # 是否隐藏大部分的控制台内容","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 保存当前目录和启动时cd到之前保存的目录，可以减少sdwui-start-new.ipynb文件下载次数\nimport os\nINIT_WORK_PATH = os.environ['HOME']\nif os.getenv('INIT_WORK_PATH',''):\n    INIT_WORK_PATH = os.getenv('INIT_WORK_PATH','')\nelse:\n    os.environ['INIT_WORK_PATH'] = os.getcwd()\n%cd {INIT_WORK_PATH}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reLoad = True\n# 如果需要重新安装，请注释下面这一行\nreLoad = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not os.path.exists('sdwui-start-util.ipynb'):\n    !wget https://huggingface.co/viyi/sdwui/resolve/main/sdwui-start-util.ipynb -o log.log\n%run sdwui-start-util.ipynb","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    check_gpu() # 检查是否存在gpu\n    main()\nexcept KeyboardInterrupt:\n    stop_solo_threads() # 中断后自动停止后台线程 （有部分功能在后台线程中运行）","metadata":{"execution":{"iopub.status.idle":"2023-09-23T13:57:33.428496Z","shell.execute_reply.started":"2023-09-23T13:56:02.582974Z","shell.execute_reply":"2023-09-23T13:57:33.427317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 打包收藏文件夹 如果需要可以取消下面两行的注释\n# zipPath('$install_path/sd_main_dir/log','log')\n# !mv {output_path}/log.tar {output_path}/log.tar.bak\n# createOrUpdateDataSet(f'{output_path}/log.tar.bak','sd-webui-log-bak')\n\n# 打包 这一行的结果是 压缩一个目录，并放在 output_path: /kaggle/working/ 目录下 名字是训练输出.tar\n# zipPath('$install_path/sd_main_dir/textual_inversion','训练输出') \n# zipPath('$install_path/sd_main_dir/outputs','outputs')\n\n# 打包venv并上传到数据集\n# zipPath('$install_path/sd_main_dir/venv','venv')\n# !mv {output_path}/venv.tar /kaggle/working/venv.tar.bak\n# createOrUpdateDataSet('/kaggle/working/venv.tar.bak','sd-webui-venv')\n\n# 打包命令参考，--exclude 可以排除不需要打包的目录\n# !tar -cf $output_path/webui.tar.bak --exclude=venv --exclude=extensions -C /sd_main_dir/ .","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 使用帮助\n---\n**代码块不能删除也不能调换顺序，如果出现变量未定义，请检查是否按顺序执行了代码块**\n\n---\n\n## kaggle账号\n- 注册账号需要手机号，国内手机号也行，如果点击注册后没反应，估计是需要梯子，用于人机验证\n- 注册后点此笔记的 **Copy & Edit** 按钮就进到编辑界面\n\n## 准备工作\n1. 右侧面板 **Notebook options/ACCELERATOR** 需要选择GPU **T4x2**出图更快\n2. 右侧面板 **Notebook options/LANGUAGE** 需要选择Python\n2. 右侧面板 **Notebook options/PERSISTENCE** 建议选择 Files only **作用是保存Outpot目录内的文件，当前这个功能并没有任何作用**\n3. 右侧面板 **Notebook options/ENVIRONMENT** 建议不改这个配置，使用当前默认值就行\n4. 右侧面板 **Notebook options/INTERNET** 需要打开 用于联网\n\n## 启动\n#### 启动方式一  **直接点击页面上边的 RunAll**\n- 手机端可能会出现页面上边的工具栏不显示的情况，左侧菜单按钮里也有相关的操作\n- 长时间不操作页面会导致脚本停止 （应该是40分钟吧）\n\n#### 启动方式二  **使用页面上边的 Save Version 后台运行**\n- 后台运行不用担心长时间不操作脚本停止\n- Version Type 选择 **Save & Run All**\n- 在Save Version弹窗里需要选择使用**GPU**环境 （Advanced Settings 里最后一个选项）\n\n## 访问\n- 如果你使用了ngrok或者frpc，可以访问你这两对应的地址\n- 如果你不知道你的ngrok或者frpc的地址可以在控制台（页面最下方Console）的输出里面查看\n- 使用Run All方式启动，控制台在启动完成后会输出访问网址，网址内容包含**gradio.live**，可以在页面中搜索快速找到\n- 如果使用Save Verson的方式启动，点击左下角的**View Active Events**点击刚刚启动的脚步，在**Log**里找访问网址\n- 一般情况下第一次启动此脚本需要等待kaggle下载模型文件，进度在页面上方\n- 第二次及以后（不增加新的文件）需要3到5分钟\n\n## 增加模型\n- 可以直接写模型的下载链接，省去下面这些步骤\n1. 先创建数据集，也就是dataset\n2. 创建时需要添加文件，选择自己的模型文件就行\n3. 同类型文件放相同的数据集里面，一个数据集也不要太大\n4. 可以在dataset搜索其他人上传的模型\n5. 通过右侧的 **Add Data** 按钮选择已经上传的模型文件或者别人上传的模型文件\n    - input 下面的列表就是模型文件，可以点击名称后面的复制按钮复制路径\n6. 将模型路径放在配置里的对应配置里即可，支持文件夹和文件路径，参考 **modelDirs**\n    - 如果目录里还有子目录也是需要加载的，可以用*表示子目录 例子：比如Loras目录下还有角色、画风、涩涩的文件夹，那路径里写成 '/kaggle/input/Loras/*'就可以加载子目录里面的文件了\n    - 模型加载使用的文件链接方式，如果你融模型的时候新模型名字和原有模型名字一样，会出现不能修改只读文件的错误\n    - 同理，直接对模型做编辑的工具可能也会出现相同的错误\n    \n \n- **受到kaggle内存大小的影响，切换多个模型后大概率爆内存导致停止运行**\n    \n**下边的配置项都写了对应配置的作用和使用说明，不理解的话也不用改，用默认的就好**\n\n## 下载文件\n#### 方式一\n- 在浏览器直接下 比如你需要下载的文件路径在 /kaggle/stable-diffusion-webui/models/Lora/dow_a.safetensors\n    - 比如你需要下载的文件路径在 /kaggle/stable-diffusion-webui/models/Lora/dow_a.safetensors\n    - 你的访问地址是 https://123123123.gradio.live\n    - 则可以在浏览器输入 https://123123123.gradio.live/file=/kaggle/stable-diffusion-webui/models/Lora/dow_a.safetensors 下载你的文件\n    \n#### 方式二\n- 复制到Output目录下载 仅支持使用Run All方式运行的\n    - 比如你需要下载的文件路径在 /kaggle/stable-diffusion-webui/models/Lora/dow_a.safetensors\n    - 先停止笔记本（不是关机，是停止）\n    - 然后新建一个代码块，在里面输入 !cp -f /kaggle/stable-diffusion-webui/models/Lora/dow_a.safetensors /kaggle/working/\n    - 或者 新建一个代码块，在里面输入 !cp -f \\$install_path/stable-diffusion-webui/models/Lora/dow_a.safetensors /kaggle/working/\n    - 你可能需要拼接路径 如果是在webui里面看到的路径，且路径里面没有带**stable-diffusion-webui**\n        - 拼接方式是 **\\$install_path/stable-diffusion-webui** + **文件路径** 拼成类似前一条的样子\n    - 就可以在右侧列表的Output目录看见复制出来的文件，点击下载即可\n\n## **一些可能没用的说明**\n- 配置说明 **True或者False**表示布尔值 **True**表示“**是**” **False**表示“**否**” 只有这两个值\n- 配置说明 **[]** 表示数组，里面可以存放内容，每个内容需要用**英语(半角)逗号**隔开\n- 配置说明 **''或者\"\"** 英语(半角)的双引号或者单引号包裹的内容是**字符串**，比如放在数组里面的路径就需要是一个字符串\n- 配置说明 **#** **#** 后面的内容是**注释**，是帮助性内容，对整个代码的执行不会有影响\n","metadata":{}},{"cell_type":"markdown","source":"# 更新记录\n#### 230920 v177\n- 默认不再开启gradio这个内网穿透\n- 更新了一些文档和说明\n#### 230910 v175\n- 增加了默认的sdxl模型\n- 修改了不合适的使用说明\n\n#### 230901 v173\n- 更新了依赖版本，可以加载sdxl模型了\n- 增加代码块内容说明，希望有用\n\n#### 230812 v171\n- 把关闭半精度的参数注释了，这是之前写错的，注释后不容易爆内存\n- 增加默认模型的参数，用于指定模型启动时默认的模型\n\n#### 230726 v170\n- 更新了整个配置，可以更加自由的下载和加载文件\n- 删除了大部分参数\n\n#### 230726 v169\n- 增加了一个文件加载配置，可以自定义把文件或下载地址加载到指定目录，配置方式见 [ 其他文件列表 ]\n- 增加了一个配置，可以隐藏部分控制台输出，但隐藏不完全，没啥用\n\n#### 230719 v168\n- 增加了同步收藏文件夹到 huggingface 数据集的功能，仅同步收藏文件夹，如果同步所有图片也太浪费资源了\n\n#### 230716 v167\n- 账号解封了\n- 已经更新为精简自动更新版，主要逻辑分离存放到 [huggingface](https://huggingface.co/viyi/sdwui)，这边基本上不再需要更新\n- 如果增加了新功能需要新的配置，可以在输出内容的最前面查看到（暂定）\n\n#### 230302 v165\n- 可以修改disableShared=True来使用pm2启动，做到爆内存自动重启（需要使用frpc或者ngrok代理，否则无法访问界面）\n\n#### 230228 v156\n- 移除了koishi的相关功能 如需使用，可查看 [sd-webui-koishi](https://www.kaggle.com/code/yiyiooo/sd-webui-koishi)\n\n#### 230227 v147\n- 增加了nginx做反向代理，现在可以使用一个ngrok地址访问多个服务了 功能在版本156移除\n\n#### 230225 v139\n- 可以加载ssl证书，启动https的隧道了\n\n#### 230224 v134\n- 可以自动修改frp的本地端口\n\n#### 230224 v128\n- 修复默认模型文件不存在时不能启动的问题\n- 修复了多线程导致依赖等内容安装位置错乱的问题\n- 修复了第一次启动会更新koishi数据对应的数据集问题\n- 增加了配置检查功能，对一些配置项做了提示\n- 增加了可配置webui端口功能，现在可以配置webui、froc、ngrok的端口了\n\n#### 230223 v126\n- 修复了仅适用koishi数据目录无法启动koishi的问题\n- 修改了部分文档\n\n#### 230223 v124\n- 修复使用多线程后出现的文件安装下载目录失败的问题\n- 修复使用多线程后文件目录错乱问题\n\n#### 230222 v123\n- 使用多线程进行安装，节省安装时间\n\n#### 230222 v122\n- 更改了默认配置，现在训练的输出可以在Output下面查看了\n\n#### 230222 v118\n- 增加了自动上传koishi的数据到数据集且能自动下载的功能\n    - 自动上传的数据集优先级高于手动上传的\n    - 上一个版本的数据集与当前版本的目录结构有差异，如果更新后需要修改配置\n    \n#### 230121 v111\n- 增加了koishi的部署相关功能  功能在版本156移除\n\n#### 230220 v110\n- 增加了ControlNet插件的一些说明\n\n#### 230220 v109\n- 修复第二次Run all时不能切换到新的frpc配置问题\n- 增加更新记录，用于记录每次更新 ","metadata":{}}]}